The parameters were set to the following:
activation: relu,  tol: 0.0001,  hidden_layer_sizes: (100,),  solver: adam,  max_iter: 1000,  early_stopping: True,  random_state: 42
All values are default values, except for max_iter, early_stopping and random_state.

Classification Report:

              precision    recall  f1-score   support

        FAKE       0.91      0.86      0.88       628
        REAL       0.87      0.91      0.89       639

    accuracy                           0.89      1267
   macro avg       0.89      0.89      0.89      1267
weighted avg       0.89      0.89      0.89      1267
