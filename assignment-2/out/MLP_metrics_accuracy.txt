The best performing parameters when tuning for accuracy:
{'MLP__activation': 'relu', 'MLP__hidden_layer_sizes': (100,), 'MLP__tol': 1e-05}

Classification Report:

              precision    recall  f1-score   support

        FAKE       0.91      0.86      0.88       628
        REAL       0.87      0.91      0.89       639

    accuracy                           0.89      1267
   macro avg       0.89      0.89      0.89      1267
weighted avg       0.89      0.89      0.89      1267


Info on the hyperparameters tuned etc. can be found in the README.md file