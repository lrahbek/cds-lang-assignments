{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline \n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LR classifier: \n",
    "The gridsearch parameters initialised for the logistic regression classifier are described and rationalised below. For more on the parameters dicussed [see the scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression).\n",
    "\n",
    "- solvers = [\"lbfgs\", \"saga\", \"liblinear\"]\n",
    "\n",
    "The solver determines the algorithm used when optimizing. Different solvers are avilable, \n",
    "'lbfgs' is robust and the default solver when using ```scikit-learn``` LogisticRegression. Additionally, 'saga' and 'liblinear' are included in the tuning. 'liblinear' is recommended on smaller datasets, which the *Fake or Real News* dataset is, and 'saga' is overall well performing. \n",
    "\n",
    "- penalties = [\"l1\", \"l2\"]\n",
    "\n",
    "*consider whether lbfgs should be included? it does not support l1 penalty*\n",
    "\n",
    "The penalties represent different regularization techinques, which helps balance between model fit and complexity. Not all solvers support all penalties, in this case 'l1' and 'l2' penalties have been included in the gridsearch. \n",
    "\n",
    "- C = [1.0, 0.1, 0.01]\n",
    "\n",
    "The C hyperparameter defines the strength of the regulrazation on the model, the smaller the value the more regulration and the simpler the model, in turn a higher value slacks the regularization and allows for a more complex model. The default is 1.0, and 0.1 and 0.01 has also been included as paramaters in the grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test, X_train, X_test, feature_names = pd.read_pickle('out/features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1267, 500)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the default model, here given the name 'classifier'\n",
    "pipe = Pipeline([('classifier' , LogisticRegression())]) #able to pass multiple classifiers to test\n",
    "# Set tunable parameters for grid search - other parameters can be set (scikit learn logreg see parameters)\n",
    "penalties = ['l1', 'l2'] # different regularization parameters\n",
    "C = [1.0, 0.1, 0.01]     # different regularization 'strengths'\n",
    "solvers = ['liblinear', \"saga\", \"lbfgs\"]  # different solvers - check all of the sklearn docs \n",
    "# Create parameter grid (a Python dictionary)\n",
    "parameters = dict(classifier__penalty = penalties,  # notice how we use the name 'classifier'\n",
    "                  classifier__C = C,\n",
    "                  classifier__solver = solvers)\n",
    "# Choose which metrics on which we want to optimise\n",
    "scores = ['precision', 'recall', 'f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on training data:\n",
      "\n",
      "{'classifier__C': 1.0, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "\n",
      "Grid scores on training data:\n",
      "\n",
      "Run 0: 0.891 (SD=±0.024), using {'classifier__C': 1.0, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Run 1: 0.891 (SD=±0.023), using {'classifier__C': 1.0, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "Run 2: 0.885 (SD=±0.034), using {'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Run 3: 0.885 (SD=±0.034), using {'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "Run 4: 0.824 (SD=±0.024), using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Run 5: 0.823 (SD=±0.024), using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "Run 6: 0.851 (SD=±0.033), using {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Run 7: 0.852 (SD=±0.033), using {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "Run 8: 0.25 (SD=±0.002), using {'classifier__C': 0.01, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Run 9: 0.25 (SD=±0.002), using {'classifier__C': 0.01, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "Run 10: 0.828 (SD=±0.028), using {'classifier__C': 0.01, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Run 11: 0.826 (SD=±0.028), using {'classifier__C': 0.01, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full training set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.89      0.87      0.88       628\n",
      "        REAL       0.87      0.90      0.89       639\n",
      "\n",
      "    accuracy                           0.88      1267\n",
      "   macro avg       0.88      0.88      0.88      1267\n",
      "weighted avg       0.88      0.88      0.88      1267\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on training data:\n",
      "\n",
      "{'classifier__C': 1.0, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "\n",
      "Grid scores on training data:\n",
      "\n",
      "Run 0: 0.891 (SD=±0.024), using {'classifier__C': 1.0, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Run 1: 0.891 (SD=±0.024), using {'classifier__C': 1.0, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "Run 2: 0.885 (SD=±0.034), using {'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Run 3: 0.885 (SD=±0.034), using {'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "Run 4: 0.822 (SD=±0.025), using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Run 5: 0.82 (SD=±0.025), using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "Run 6: 0.851 (SD=±0.033), using {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Run 7: 0.851 (SD=±0.033), using {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "Run 8: 0.5 (SD=±0.002), using {'classifier__C': 0.01, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Run 9: 0.5 (SD=±0.002), using {'classifier__C': 0.01, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "Run 10: 0.828 (SD=±0.028), using {'classifier__C': 0.01, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Run 11: 0.825 (SD=±0.027), using {'classifier__C': 0.01, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full training set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.89      0.87      0.88       628\n",
      "        REAL       0.87      0.90      0.89       639\n",
      "\n",
      "    accuracy                           0.88      1267\n",
      "   macro avg       0.88      0.88      0.88      1267\n",
      "weighted avg       0.88      0.88      0.88      1267\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on training data:\n",
      "\n",
      "{'classifier__C': 1.0, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "\n",
      "Grid scores on training data:\n",
      "\n",
      "Run 0: 0.891 (SD=±0.024), using {'classifier__C': 1.0, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Run 1: 0.891 (SD=±0.023), using {'classifier__C': 1.0, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "Run 2: 0.885 (SD=±0.034), using {'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Run 3: 0.885 (SD=±0.034), using {'classifier__C': 1.0, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "Run 4: 0.822 (SD=±0.025), using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Run 5: 0.821 (SD=±0.025), using {'classifier__C': 0.1, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "Run 6: 0.851 (SD=±0.033), using {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Run 7: 0.851 (SD=±0.033), using {'classifier__C': 0.1, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "Run 8: 0.334 (SD=±0.002), using {'classifier__C': 0.01, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n",
      "Run 9: 0.333 (SD=±0.002), using {'classifier__C': 0.01, 'classifier__penalty': 'l1', 'classifier__solver': 'saga'}\n",
      "Run 10: 0.827 (SD=±0.028), using {'classifier__C': 0.01, 'classifier__penalty': 'l2', 'classifier__solver': 'liblinear'}\n",
      "Run 11: 0.825 (SD=±0.027), using {'classifier__C': 0.01, 'classifier__penalty': 'l2', 'classifier__solver': 'saga'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full training set.\n",
      "The scores are computed on the full test set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.89      0.87      0.88       628\n",
      "        REAL       0.87      0.90      0.89       639\n",
      "\n",
      "    accuracy                           0.88      1267\n",
      "   macro avg       0.88      0.88      0.88      1267\n",
      "weighted avg       0.88      0.88      0.88      1267\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ucloud/.local/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for score in scores:\n",
    "    print(f\"# Tuning hyper-parameters for {score}\")\n",
    "    print()\n",
    "    \n",
    "    # Initialise Gridsearch with predefined parameters \n",
    "    clf = GridSearchCV(pipe,                                #the initialised pipeline logreg\n",
    "                       parameters,                          #the parameters defined as dict\n",
    "                       scoring= f\"{score}_weighted\",\n",
    "                       cv=10) # use 10-fold cross-validation, running the model 10 times on diff shuffles, to get averages\n",
    "    # Fit\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Print best results on training data\n",
    "    print(\"Best parameters set found on training data:\")\n",
    "    # add new lines to separate rows\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on training data:\")\n",
    "    print()\n",
    "    # get all means\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    # get all standard deviations\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    # get parameter combinations\n",
    "    params = clf.cv_results_['params']\n",
    "\n",
    "    # print means, standard deviations , and parameters for all runs\n",
    "    i = 0\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        # 2*standard deviation covers 95% of the spread - check out the 68–95–99.7 rule\n",
    "        print(f\"Run {i}: {round(mean,3)} (SD=±{round(stdev*2, 3)}), using {param}\")\n",
    "        i += 1\n",
    "    print()\n",
    "    \n",
    "    # Print details classification report\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full training set.\")\n",
    "    print(\"The scores are computed on the full test set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
