# Assignment 5 - Evaluating Environmental Impact of Exam Portfolio

*Date: 02/05/2024*

Laura Givskov Rahbek 

## Description 

This folder contains assignment 5 for Language Analytics. The objective of the assignment is to think critically about the effects and impact machhine learne has on the environment, to write code that can extract approximate benchmarks showing this impact and to present and discuss the results in an understandable way. More specifically, the package ```CodeCarbon```'s class ```EmissionsTracker``` is utilised to measure the approximate CO₂-equivalents (CO₂eq) in kg for assignments 1-4 in this repository. The resulting values are used to investigate the environmental impact of the different tasks performed in the four previous assignments done in this class. 

The ```assignment-5``` folder contains two folders: 
- An ```out``` folder which contains the .csv files with the emission data from each of the four assignments. 
- A ```src``` folder containing the notebook ```emissions.ipynb```, the handeling of the emissions data and subsequent visualization used for analysis is in this notebook. 


## Usage and Reproducing of Analysis

All code used to handle the emmisions data as well as visualisations of these can be found in the notebook in the ```src``` folder. Packages and dependencies to the run the notebook can be installed by running the bash script ```setup.sh```. To view the packages that are installed when running this, see the ```requirements.txt``` file. 

To track the emissions from the assignments the ```EmissionTracker``` from ```CoddeCarbon``` was used, to see how precisely this was done, the code can be found in the scripts in the assignments. Essentially, the tracker was initialised and then used to track different taksks, to be able to investigate the individual tasks as well as the overall impact of each assignment. The emissions were added up to infer the total emissions per assignment. 

## Discussion 

Before discussing the results of the environmental impact analysis, it is worth noting that these values are estimates and approximation to the actual emissions caused by the code run in these assignments. However, these results leads to important considerations when it comes to the cost of machine learning. I find it important to consider these costs when doing machine learning in general, and ```CodeCarbon``` is a good option when for this. However, none of the code, analysis or machine learning conducted for this exam is of great importance to anything except for learning which is why it has been done. I would not be able to argue that it is worth the substantial amount of CO₂eq to analyse the emotional differences during Game of Thrones, based only on the scripts. Considerations discussed are therefore concerned with the general use of machine learning, and the considerations when e.g. implementing grid search or using a much more expensive model that only does marginally better than a less expensive one. 

The overall emissions for each assignment can be seen in the table below 

- Which assignment generated the most emissions in terms of CO₂eq? Explain why this might be.


|Assignment  | Emissions (CO₂eq)|
|------------|:----------------:|
|Assignment 1|0.001807          |
|Assignment 2|                  |
|Assignment 3|0.000123          |
|Assignment 4|0.047947          |

The full view of the individual tasks' generated emissions can be found in the ```out``` folder, in the .csv files generated by ```CodeCarbon``` and in the ```emissions.ipynb``` notebook as a dataframe. Below I have extracted some examples to visualise ....

- Which specific tasks generated the most emissions in terms of CO₂eq? Again, explain why this might be.

As discussed above, a great cost comes with finetuning large models, like the MLP neural network in Assignment 2. 

- How robust do you think these results are and how/where might they be improved? 

*change code to have less enviormental impact*

